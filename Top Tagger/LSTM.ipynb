{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import load_model\n",
    "from keras.models import model_from_json\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import numpy as np\n",
    "import os\n",
    "import h5py\n",
    "import yaml\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys, os\n",
    "sys.path.append(os.path.join(os.path.dirname(sys.path[0]),'lib'))\n",
    "\n",
    "from train import parse_config, get_features, print_model_to_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam, Nadam\n",
    "from callbacks import all_callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading configuration from ../train/train_config_lstm.yml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Inputs': ['j1_ptrel',\n",
       "  'j1_etarot',\n",
       "  'j1_phirot',\n",
       "  'j1_erel',\n",
       "  'j1_deltaR',\n",
       "  'j1_pdgid',\n",
       "  'j_index'],\n",
       " 'Labels': ['j_g', 'j_q', 'j_w', 'j_z', 'j_t', 'j_index'],\n",
       " 'KerasModel': 'lstm_model',\n",
       " 'KerasModelRetrain': 'lstm_model_constraint',\n",
       " 'KerasLoss': 'categorical_crossentropy',\n",
       " 'L1Reg': 0.0001,\n",
       " 'L1RegR': 0.001,\n",
       " 'NormalizeInputs': 1,\n",
       " 'InputType': 'Conv1D',\n",
       " 'MaxParticles': 20}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from collections import namedtuple\n",
    "Option = namedtuple(\"MyStruct\", \"inputModel inputFile tree config jsonModel\")\n",
    "\n",
    "options = Option(\n",
    "    inputModel = '../KERAS_lstm_model_weights.h5',\n",
    "    inputFile = '../data/processed-pythia82-lhc13-all-pt1-50k-r1_h022_e0175_t220_nonu_withPars_truth_0.z',\n",
    "    tree = 't_allpar_new',\n",
    "    config = '../train/train_config_lstm.yml',\n",
    "    jsonModel = '../KERAS_lstm_model.json'\n",
    ")\n",
    "\n",
    "print(\"Loading configuration from\", options.config)\n",
    "config = open(options.config, 'r')\n",
    "yamlConfig =  yaml.load(config, Loader=yaml.FullLoader)\n",
    "\n",
    "yamlConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5131613,)\n",
      "('index', 'j_ptfrac', 'j_pt', 'j_eta', 'j_mass', 'j_tau1_b1', 'j_tau2_b1', 'j_tau3_b1', 'j_tau1_b2', 'j_tau2_b2', 'j_tau3_b2', 'j_tau32_b1', 'j_tau32_b2', 'j_zlogz', 'j_c1_b0', 'j_c1_b1', 'j_c1_b2', 'j_c2_b1', 'j_c2_b2', 'j_d2_b1', 'j_d2_b2', 'j_d2_a1_b1', 'j_d2_a1_b2', 'j_m2_b1', 'j_m2_b2', 'j_n2_b1', 'j_n2_b2', 'j_tau1_b1_mmdt', 'j_tau2_b1_mmdt', 'j_tau3_b1_mmdt', 'j_tau1_b2_mmdt', 'j_tau2_b2_mmdt', 'j_tau3_b2_mmdt', 'j_tau32_b1_mmdt', 'j_tau32_b2_mmdt', 'j_c1_b0_mmdt', 'j_c1_b1_mmdt', 'j_c1_b2_mmdt', 'j_c2_b1_mmdt', 'j_c2_b2_mmdt', 'j_d2_b1_mmdt', 'j_d2_b2_mmdt', 'j_d2_a1_b1_mmdt', 'j_d2_a1_b2_mmdt', 'j_m2_b1_mmdt', 'j_m2_b2_mmdt', 'j_n2_b1_mmdt', 'j_n2_b2_mmdt', 'j_mass_trim', 'j_mass_mmdt', 'j_mass_prun', 'j_mass_sdb2', 'j_mass_sdm1', 'j_multiplicity', 'j1_px', 'j1_py', 'j1_pz', 'j1_e', 'j1_pdgid', 'j1_erel', 'j1_pt', 'j1_ptrel', 'j1_eta', 'j1_etarel', 'j1_etarot', 'j1_phi', 'j1_phirel', 'j1_phirot', 'j1_deltaR', 'j1_costheta', 'j1_costhetarel', 'j1_e1mcosthetarel', 'j_g', 'j_q', 'j_w', 'j_z', 'j_t', 'j_undef', 'j_index')\n",
      "(98769, 5)\n"
     ]
    }
   ],
   "source": [
    "X_train_val, X_test, y_train_val, y_test, labels  = get_features(options, yamlConfig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file = open(options.jsonModel, 'r')\n",
    "model = model_from_json(json_file.read())\n",
    "json_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 20, 6)             0         \n",
      "_________________________________________________________________\n",
      "lstm_lstm (LSTM)             (None, 20, 16)            1472      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 320)               0         \n",
      "_________________________________________________________________\n",
      "rnn_densef (Dense)           (None, 5)                 1605      \n",
      "=================================================================\n",
      "Total params: 3,077\n",
      "Trainable params: 3,077\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 20, 6)             0         \n",
      "_________________________________________________________________\n",
      "lstm_lstm (LSTM)             (None, 20, 16)            1472      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 320)               0         \n",
      "_________________________________________________________________\n",
      "rnn_densef (Dense)           (None, 5)                 1605      \n",
      "=================================================================\n",
      "Total params: 3,077\n",
      "Trainable params: 3,077\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 59261 samples, validate on 19754 samples\n",
      "Epoch 1/100\n",
      "56320/59261 [===========================>..] - ETA: 0s - loss: 2.8924 - acc: 0.3342\n",
      "***callbacks***\n",
      "saving losses to .\\training_callbacks\\losses.log\n",
      "Epoch 00000: val_loss improved from inf to 1.85241, saving model to .\\training_callbacks/KERAS_check_best_model.h5\n",
      "Epoch 00000: val_loss improved from inf to 1.85241, saving model to .\\training_callbacks/KERAS_check_best_model_weights.h5\n",
      "Epoch 00000: saving model to .\\training_callbacks/KERAS_check_model_last.h5\n",
      "Epoch 00000: saving model to .\\training_callbacks/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "59261/59261 [==============================] - 2s - loss: 2.8435 - acc: 0.3392 - val_loss: 1.8524 - val_acc: 0.4382\n",
      "Epoch 2/100\n",
      "56320/59261 [===========================>..] - ETA: 0s - loss: 1.6552 - acc: 0.4670\n",
      "***callbacks***\n",
      "saving losses to .\\training_callbacks\\losses.log\n",
      "Epoch 00001: val_loss improved from 1.85241 to 1.52050, saving model to .\\training_callbacks/KERAS_check_best_model.h5\n",
      "Epoch 00001: val_loss improved from 1.85241 to 1.52050, saving model to .\\training_callbacks/KERAS_check_best_model_weights.h5\n",
      "Epoch 00001: saving model to .\\training_callbacks/KERAS_check_model_last.h5\n",
      "Epoch 00001: saving model to .\\training_callbacks/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "59261/59261 [==============================] - 1s - loss: 1.6500 - acc: 0.4676 - val_loss: 1.5205 - val_acc: 0.4817\n",
      "Epoch 3/100\n",
      "56320/59261 [===========================>..] - ETA: 0s - loss: 1.4876 - acc: 0.4939\n",
      "***callbacks***\n",
      "saving losses to .\\training_callbacks\\losses.log\n",
      "Epoch 00002: val_loss improved from 1.52050 to 1.43095, saving model to .\\training_callbacks/KERAS_check_best_model.h5\n",
      "Epoch 00002: val_loss improved from 1.52050 to 1.43095, saving model to .\\training_callbacks/KERAS_check_best_model_weights.h5\n",
      "Epoch 00002: saving model to .\\training_callbacks/KERAS_check_model_last.h5\n",
      "Epoch 00002: saving model to .\\training_callbacks/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "59261/59261 [==============================] - 1s - loss: 1.4864 - acc: 0.4937 - val_loss: 1.4309 - val_acc: 0.4986\n",
      "Epoch 4/100\n",
      "56320/59261 [===========================>..] - ETA: 0s - loss: 1.4183 - acc: 0.5064\n",
      "***callbacks***\n",
      "saving losses to .\\training_callbacks\\losses.log\n",
      "Epoch 00003: val_loss improved from 1.43095 to 1.37558, saving model to .\\training_callbacks/KERAS_check_best_model.h5\n",
      "Epoch 00003: val_loss improved from 1.43095 to 1.37558, saving model to .\\training_callbacks/KERAS_check_best_model_weights.h5\n",
      "Epoch 00003: saving model to .\\training_callbacks/KERAS_check_model_last.h5\n",
      "Epoch 00003: saving model to .\\training_callbacks/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "59261/59261 [==============================] - 1s - loss: 1.4165 - acc: 0.5071 - val_loss: 1.3756 - val_acc: 0.5108\n",
      "Epoch 5/100\n",
      "56320/59261 [===========================>..] - ETA: 0s - loss: 1.3691 - acc: 0.5160\n",
      "***callbacks***\n",
      "saving losses to .\\training_callbacks\\losses.log\n",
      "Epoch 00004: val_loss improved from 1.37558 to 1.33482, saving model to .\\training_callbacks/KERAS_check_best_model.h5\n",
      "Epoch 00004: val_loss improved from 1.37558 to 1.33482, saving model to .\\training_callbacks/KERAS_check_best_model_weights.h5\n",
      "Epoch 00004: saving model to .\\training_callbacks/KERAS_check_model_last.h5\n",
      "Epoch 00004: saving model to .\\training_callbacks/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "59261/59261 [==============================] - 1s - loss: 1.3675 - acc: 0.5157 - val_loss: 1.3348 - val_acc: 0.5177\n",
      "Epoch 6/100\n",
      "56320/59261 [===========================>..] - ETA: 0s - loss: 1.3298 - acc: 0.5229\n",
      "***callbacks***\n",
      "saving losses to .\\training_callbacks\\losses.log\n",
      "Epoch 00005: val_loss improved from 1.33482 to 1.30223, saving model to .\\training_callbacks/KERAS_check_best_model.h5\n",
      "Epoch 00005: val_loss improved from 1.33482 to 1.30223, saving model to .\\training_callbacks/KERAS_check_best_model_weights.h5\n",
      "Epoch 00005: saving model to .\\training_callbacks/KERAS_check_model_last.h5\n",
      "Epoch 00005: saving model to .\\training_callbacks/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "59261/59261 [==============================] - 1s - loss: 1.3301 - acc: 0.5229 - val_loss: 1.3022 - val_acc: 0.5229\n",
      "Epoch 7/100\n",
      "58368/59261 [============================>.] - ETA: 0s - loss: 1.3005 - acc: 0.5287\n",
      "***callbacks***\n",
      "saving losses to .\\training_callbacks\\losses.log\n",
      "Epoch 00006: val_loss improved from 1.30223 to 1.27705, saving model to .\\training_callbacks/KERAS_check_best_model.h5\n",
      "Epoch 00006: val_loss improved from 1.30223 to 1.27705, saving model to .\\training_callbacks/KERAS_check_best_model_weights.h5\n",
      "Epoch 00006: saving model to .\\training_callbacks/KERAS_check_model_last.h5\n",
      "Epoch 00006: saving model to .\\training_callbacks/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "59261/59261 [==============================] - 1s - loss: 1.3001 - acc: 0.5282 - val_loss: 1.2771 - val_acc: 0.5290\n",
      "Epoch 8/100\n",
      "56320/59261 [===========================>..] - ETA: 0s - loss: 1.2755 - acc: 0.5340- ETA: 0s - loss: 1.2760 - acc: 0.534\n",
      "***callbacks***\n",
      "saving losses to .\\training_callbacks\\losses.log\n",
      "Epoch 00007: val_loss improved from 1.27705 to 1.25582, saving model to .\\training_callbacks/KERAS_check_best_model.h5\n",
      "Epoch 00007: val_loss improved from 1.27705 to 1.25582, saving model to .\\training_callbacks/KERAS_check_best_model_weights.h5\n",
      "Epoch 00007: saving model to .\\training_callbacks/KERAS_check_model_last.h5\n",
      "Epoch 00007: saving model to .\\training_callbacks/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "59261/59261 [==============================] - 1s - loss: 1.2759 - acc: 0.5339 - val_loss: 1.2558 - val_acc: 0.5329\n",
      "Epoch 9/100\n",
      "56320/59261 [===========================>..] - ETA: 0s - loss: 1.2574 - acc: 0.5389\n",
      "***callbacks***\n",
      "saving losses to .\\training_callbacks\\losses.log\n",
      "Epoch 00008: val_loss improved from 1.25582 to 1.23917, saving model to .\\training_callbacks/KERAS_check_best_model.h5\n",
      "Epoch 00008: val_loss improved from 1.25582 to 1.23917, saving model to .\\training_callbacks/KERAS_check_best_model_weights.h5\n",
      "Epoch 00008: saving model to .\\training_callbacks/KERAS_check_model_last.h5\n",
      "Epoch 00008: saving model to .\\training_callbacks/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "59261/59261 [==============================] - 1s - loss: 1.2560 - acc: 0.5388 - val_loss: 1.2392 - val_acc: 0.5372\n",
      "Epoch 10/100\n",
      "56320/59261 [===========================>..] - ETA: 0s - loss: 1.2410 - acc: 0.5430\n",
      "***callbacks***\n",
      "saving losses to .\\training_callbacks\\losses.log\n",
      "Epoch 00009: val_loss improved from 1.23917 to 1.22484, saving model to .\\training_callbacks/KERAS_check_best_model.h5\n",
      "Epoch 00009: val_loss improved from 1.23917 to 1.22484, saving model to .\\training_callbacks/KERAS_check_best_model_weights.h5\n",
      "Epoch 00009: saving model to .\\training_callbacks/KERAS_check_model_last.h5\n",
      "Epoch 00009: saving model to .\\training_callbacks/KERAS_check_model_last_weights.h5\n",
      "Epoch 00009: saving model to .\\training_callbacks/KERAS_check_model_epoch09.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "59261/59261 [==============================] - 1s - loss: 1.2396 - acc: 0.5434 - val_loss: 1.2248 - val_acc: 0.5409\n",
      "Epoch 11/100\n",
      "56320/59261 [===========================>..] - ETA: 0s - loss: 1.2265 - acc: 0.5461\n",
      "***callbacks***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving losses to .\\training_callbacks\\losses.log\n",
      "Epoch 00010: val_loss improved from 1.22484 to 1.21254, saving model to .\\training_callbacks/KERAS_check_best_model.h5\n",
      "Epoch 00010: val_loss improved from 1.22484 to 1.21254, saving model to .\\training_callbacks/KERAS_check_best_model_weights.h5\n",
      "Epoch 00010: saving model to .\\training_callbacks/KERAS_check_model_last.h5\n",
      "Epoch 00010: saving model to .\\training_callbacks/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "59261/59261 [==============================] - 1s - loss: 1.2259 - acc: 0.5466 - val_loss: 1.2125 - val_acc: 0.5453\n",
      "Epoch 12/100\n",
      "56320/59261 [===========================>..] - ETA: 0s - loss: 1.2148 - acc: 0.5501\n",
      "***callbacks***\n",
      "saving losses to .\\training_callbacks\\losses.log\n",
      "Epoch 00011: val_loss improved from 1.21254 to 1.20228, saving model to .\\training_callbacks/KERAS_check_best_model.h5\n",
      "Epoch 00011: val_loss improved from 1.21254 to 1.20228, saving model to .\\training_callbacks/KERAS_check_best_model_weights.h5\n",
      "Epoch 00011: saving model to .\\training_callbacks/KERAS_check_model_last.h5\n",
      "Epoch 00011: saving model to .\\training_callbacks/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "59261/59261 [==============================] - 1s - loss: 1.2139 - acc: 0.5506 - val_loss: 1.2023 - val_acc: 0.5498\n",
      "Epoch 13/100\n",
      "56320/59261 [===========================>..] - ETA: 0s - loss: 1.2045 - acc: 0.5547\n",
      "***callbacks***\n",
      "saving losses to .\\training_callbacks\\losses.log\n",
      "Epoch 00012: val_loss improved from 1.20228 to 1.19341, saving model to .\\training_callbacks/KERAS_check_best_model.h5\n",
      "Epoch 00012: val_loss improved from 1.20228 to 1.19341, saving model to .\\training_callbacks/KERAS_check_best_model_weights.h5\n",
      "Epoch 00012: saving model to .\\training_callbacks/KERAS_check_model_last.h5\n",
      "Epoch 00012: saving model to .\\training_callbacks/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "59261/59261 [==============================] - 1s - loss: 1.2040 - acc: 0.5548 - val_loss: 1.1934 - val_acc: 0.5520\n",
      "Epoch 14/100\n",
      "56320/59261 [===========================>..] - ETA: 0s - loss: 1.1950 - acc: 0.5580\n",
      "***callbacks***\n",
      "saving losses to .\\training_callbacks\\losses.log\n",
      "Epoch 00013: val_loss improved from 1.19341 to 1.18626, saving model to .\\training_callbacks/KERAS_check_best_model.h5\n",
      "Epoch 00013: val_loss improved from 1.19341 to 1.18626, saving model to .\\training_callbacks/KERAS_check_best_model_weights.h5\n",
      "Epoch 00013: saving model to .\\training_callbacks/KERAS_check_model_last.h5\n",
      "Epoch 00013: saving model to .\\training_callbacks/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "59261/59261 [==============================] - 1s - loss: 1.1951 - acc: 0.5577 - val_loss: 1.1863 - val_acc: 0.5549\n",
      "Epoch 15/100\n",
      "56320/59261 [===========================>..] - ETA: 0s - loss: 1.1866 - acc: 0.5615\n",
      "***callbacks***\n",
      "saving losses to .\\training_callbacks\\losses.log\n",
      "Epoch 00014: val_loss improved from 1.18626 to 1.17868, saving model to .\\training_callbacks/KERAS_check_best_model.h5\n",
      "Epoch 00014: val_loss improved from 1.18626 to 1.17868, saving model to .\\training_callbacks/KERAS_check_best_model_weights.h5\n",
      "Epoch 00014: saving model to .\\training_callbacks/KERAS_check_model_last.h5\n",
      "Epoch 00014: saving model to .\\training_callbacks/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "59261/59261 [==============================] - 1s - loss: 1.1873 - acc: 0.5618 - val_loss: 1.1787 - val_acc: 0.5594\n",
      "Epoch 16/100\n",
      "56320/59261 [===========================>..] - ETA: 0s - loss: 1.1810 - acc: 0.5646\n",
      "***callbacks***\n",
      "saving losses to .\\training_callbacks\\losses.log\n",
      "Epoch 00015: val_loss improved from 1.17868 to 1.17242, saving model to .\\training_callbacks/KERAS_check_best_model.h5\n",
      "Epoch 00015: val_loss improved from 1.17868 to 1.17242, saving model to .\\training_callbacks/KERAS_check_best_model_weights.h5\n",
      "Epoch 00015: saving model to .\\training_callbacks/KERAS_check_model_last.h5\n",
      "Epoch 00015: saving model to .\\training_callbacks/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "59261/59261 [==============================] - 1s - loss: 1.1800 - acc: 0.5645 - val_loss: 1.1724 - val_acc: 0.5620\n",
      "Epoch 17/100\n",
      "56320/59261 [===========================>..] - ETA: 0s - loss: 1.1743 - acc: 0.5678\n",
      "***callbacks***\n",
      "saving losses to .\\training_callbacks\\losses.log\n",
      "Epoch 00016: val_loss improved from 1.17242 to 1.16643, saving model to .\\training_callbacks/KERAS_check_best_model.h5\n",
      "Epoch 00016: val_loss improved from 1.17242 to 1.16643, saving model to .\\training_callbacks/KERAS_check_best_model_weights.h5\n",
      "Epoch 00016: saving model to .\\training_callbacks/KERAS_check_model_last.h5\n",
      "Epoch 00016: saving model to .\\training_callbacks/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "59261/59261 [==============================] - 1s - loss: 1.1734 - acc: 0.5682 - val_loss: 1.1664 - val_acc: 0.5651\n",
      "Epoch 18/100\n",
      "56320/59261 [===========================>..] - ETA: 0s - loss: 1.1687 - acc: 0.5705\n",
      "***callbacks***\n",
      "saving losses to .\\training_callbacks\\losses.log\n",
      "Epoch 00017: val_loss improved from 1.16643 to 1.16126, saving model to .\\training_callbacks/KERAS_check_best_model.h5\n",
      "Epoch 00017: val_loss improved from 1.16643 to 1.16126, saving model to .\\training_callbacks/KERAS_check_best_model_weights.h5\n",
      "Epoch 00017: saving model to .\\training_callbacks/KERAS_check_model_last.h5\n",
      "Epoch 00017: saving model to .\\training_callbacks/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "59261/59261 [==============================] - 1s - loss: 1.1676 - acc: 0.5711 - val_loss: 1.1613 - val_acc: 0.5662\n",
      "Epoch 19/100\n",
      "56320/59261 [===========================>..] - ETA: 0s - loss: 1.1610 - acc: 0.5731\n",
      "***callbacks***\n",
      "saving losses to .\\training_callbacks\\losses.log\n",
      "Epoch 00018: val_loss improved from 1.16126 to 1.15630, saving model to .\\training_callbacks/KERAS_check_best_model.h5\n",
      "Epoch 00018: val_loss improved from 1.16126 to 1.15630, saving model to .\\training_callbacks/KERAS_check_best_model_weights.h5\n",
      "Epoch 00018: saving model to .\\training_callbacks/KERAS_check_model_last.h5\n",
      "Epoch 00018: saving model to .\\training_callbacks/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "59261/59261 [==============================] - 1s - loss: 1.1619 - acc: 0.5728 - val_loss: 1.1563 - val_acc: 0.5699\n",
      "Epoch 20/100\n",
      "56320/59261 [===========================>..] - ETA: 0s - loss: 1.1578 - acc: 0.5759\n",
      "***callbacks***\n",
      "saving losses to .\\training_callbacks\\losses.log\n",
      "Epoch 00019: val_loss improved from 1.15630 to 1.15128, saving model to .\\training_callbacks/KERAS_check_best_model.h5\n",
      "Epoch 00019: val_loss improved from 1.15630 to 1.15128, saving model to .\\training_callbacks/KERAS_check_best_model_weights.h5\n",
      "Epoch 00019: saving model to .\\training_callbacks/KERAS_check_model_last.h5\n",
      "Epoch 00019: saving model to .\\training_callbacks/KERAS_check_model_last_weights.h5\n",
      "Epoch 00019: saving model to .\\training_callbacks/KERAS_check_model_epoch19.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "59261/59261 [==============================] - 1s - loss: 1.1568 - acc: 0.5761 - val_loss: 1.1513 - val_acc: 0.5726\n",
      "Epoch 21/100\n",
      "56320/59261 [===========================>..] - ETA: 0s - loss: 1.1525 - acc: 0.5788\n",
      "***callbacks***\n",
      "saving losses to .\\training_callbacks\\losses.log\n",
      "Epoch 00020: val_loss improved from 1.15128 to 1.14710, saving model to .\\training_callbacks/KERAS_check_best_model.h5\n",
      "Epoch 00020: val_loss improved from 1.15128 to 1.14710, saving model to .\\training_callbacks/KERAS_check_best_model_weights.h5\n",
      "Epoch 00020: saving model to .\\training_callbacks/KERAS_check_model_last.h5\n",
      "Epoch 00020: saving model to .\\training_callbacks/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "59261/59261 [==============================] - 1s - loss: 1.1518 - acc: 0.5788 - val_loss: 1.1471 - val_acc: 0.5738\n",
      "Epoch 22/100\n",
      "56320/59261 [===========================>..] - ETA: 0s - loss: 1.1473 - acc: 0.5810\n",
      "***callbacks***\n",
      "saving losses to .\\training_callbacks\\losses.log\n",
      "Epoch 00021: val_loss improved from 1.14710 to 1.14238, saving model to .\\training_callbacks/KERAS_check_best_model.h5\n",
      "Epoch 00021: val_loss improved from 1.14710 to 1.14238, saving model to .\\training_callbacks/KERAS_check_best_model_weights.h5\n",
      "Epoch 00021: saving model to .\\training_callbacks/KERAS_check_model_last.h5\n",
      "Epoch 00021: saving model to .\\training_callbacks/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59261/59261 [==============================] - 1s - loss: 1.1471 - acc: 0.5808 - val_loss: 1.1424 - val_acc: 0.5768\n",
      "Epoch 23/100\n",
      "56320/59261 [===========================>..] - ETA: 0s - loss: 1.1443 - acc: 0.5828- ETA: 0s - loss: 1.1337 \n",
      "***callbacks***\n",
      "saving losses to .\\training_callbacks\\losses.log\n",
      "Epoch 00022: val_loss improved from 1.14238 to 1.13818, saving model to .\\training_callbacks/KERAS_check_best_model.h5\n",
      "Epoch 00022: val_loss improved from 1.14238 to 1.13818, saving model to .\\training_callbacks/KERAS_check_best_model_weights.h5\n",
      "Epoch 00022: saving model to .\\training_callbacks/KERAS_check_model_last.h5\n",
      "Epoch 00022: saving model to .\\training_callbacks/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "59261/59261 [==============================] - 1s - loss: 1.1426 - acc: 0.5833 - val_loss: 1.1382 - val_acc: 0.5795\n",
      "Epoch 24/100\n",
      "56320/59261 [===========================>..] - ETA: 0s - loss: 1.1389 - acc: 0.5853\n",
      "***callbacks***\n",
      "saving losses to .\\training_callbacks\\losses.log\n",
      "Epoch 00023: val_loss improved from 1.13818 to 1.13462, saving model to .\\training_callbacks/KERAS_check_best_model.h5\n",
      "Epoch 00023: val_loss improved from 1.13818 to 1.13462, saving model to .\\training_callbacks/KERAS_check_best_model_weights.h5\n",
      "Epoch 00023: saving model to .\\training_callbacks/KERAS_check_model_last.h5\n",
      "Epoch 00023: saving model to .\\training_callbacks/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "59261/59261 [==============================] - 1s - loss: 1.1382 - acc: 0.5852 - val_loss: 1.1346 - val_acc: 0.5801\n",
      "Epoch 25/100\n",
      "56320/59261 [===========================>..] - ETA: 0s - loss: 1.1336 - acc: 0.5880\n",
      "***callbacks***\n",
      "saving losses to .\\training_callbacks\\losses.log\n",
      "Epoch 00024: val_loss improved from 1.13462 to 1.13119, saving model to .\\training_callbacks/KERAS_check_best_model.h5\n",
      "Epoch 00024: val_loss improved from 1.13462 to 1.13119, saving model to .\\training_callbacks/KERAS_check_best_model_weights.h5\n",
      "Epoch 00024: saving model to .\\training_callbacks/KERAS_check_model_last.h5\n",
      "Epoch 00024: saving model to .\\training_callbacks/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "59261/59261 [==============================] - 1s - loss: 1.1342 - acc: 0.5872 - val_loss: 1.1312 - val_acc: 0.5818\n",
      "Epoch 26/100\n",
      "56320/59261 [===========================>..] - ETA: 0s - loss: 1.1298 - acc: 0.5901\n",
      "***callbacks***\n",
      "saving losses to .\\training_callbacks\\losses.log\n",
      "Epoch 00025: val_loss improved from 1.13119 to 1.12774, saving model to .\\training_callbacks/KERAS_check_best_model.h5\n",
      "Epoch 00025: val_loss improved from 1.13119 to 1.12774, saving model to .\\training_callbacks/KERAS_check_best_model_weights.h5\n",
      "Epoch 00025: saving model to .\\training_callbacks/KERAS_check_model_last.h5\n",
      "Epoch 00025: saving model to .\\training_callbacks/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "59261/59261 [==============================] - 1s - loss: 1.1304 - acc: 0.5901 - val_loss: 1.1277 - val_acc: 0.5846\n",
      "Epoch 27/100\n",
      "56320/59261 [===========================>..] - ETA: 0s - loss: 1.1279 - acc: 0.5917\n",
      "***callbacks***\n",
      "saving losses to .\\training_callbacks\\losses.log\n",
      "Epoch 00026: val_loss improved from 1.12774 to 1.12412, saving model to .\\training_callbacks/KERAS_check_best_model.h5\n",
      "Epoch 00026: val_loss improved from 1.12774 to 1.12412, saving model to .\\training_callbacks/KERAS_check_best_model_weights.h5\n",
      "Epoch 00026: saving model to .\\training_callbacks/KERAS_check_model_last.h5\n",
      "Epoch 00026: saving model to .\\training_callbacks/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "59261/59261 [==============================] - 1s - loss: 1.1266 - acc: 0.5917 - val_loss: 1.1241 - val_acc: 0.5861\n",
      "Epoch 28/100\n",
      "56320/59261 [===========================>..] - ETA: 0s - loss: 1.1223 - acc: 0.5940\n",
      "***callbacks***\n",
      "saving losses to .\\training_callbacks\\losses.log\n",
      "Epoch 00027: val_loss improved from 1.12412 to 1.12034, saving model to .\\training_callbacks/KERAS_check_best_model.h5\n",
      "Epoch 00027: val_loss improved from 1.12412 to 1.12034, saving model to .\\training_callbacks/KERAS_check_best_model_weights.h5\n",
      "Epoch 00027: saving model to .\\training_callbacks/KERAS_check_model_last.h5\n",
      "Epoch 00027: saving model to .\\training_callbacks/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "59261/59261 [==============================] - 1s - loss: 1.1228 - acc: 0.5938 - val_loss: 1.1203 - val_acc: 0.5892\n",
      "Epoch 29/100\n",
      "56320/59261 [===========================>..] - ETA: 0s - loss: 1.1197 - acc: 0.5955\n",
      "***callbacks***\n",
      "saving losses to .\\training_callbacks\\losses.log\n",
      "Epoch 00028: val_loss improved from 1.12034 to 1.11749, saving model to .\\training_callbacks/KERAS_check_best_model.h5\n",
      "Epoch 00028: val_loss improved from 1.12034 to 1.11749, saving model to .\\training_callbacks/KERAS_check_best_model_weights.h5\n",
      "Epoch 00028: saving model to .\\training_callbacks/KERAS_check_model_last.h5\n",
      "Epoch 00028: saving model to .\\training_callbacks/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "59261/59261 [==============================] - 1s - loss: 1.1193 - acc: 0.5957 - val_loss: 1.1175 - val_acc: 0.5910\n",
      "Epoch 30/100\n",
      "56320/59261 [===========================>..] - ETA: 0s - loss: 1.1157 - acc: 0.5975\n",
      "***callbacks***\n",
      "saving losses to .\\training_callbacks\\losses.log\n",
      "Epoch 00029: val_loss improved from 1.11749 to 1.11399, saving model to .\\training_callbacks/KERAS_check_best_model.h5\n",
      "Epoch 00029: val_loss improved from 1.11749 to 1.11399, saving model to .\\training_callbacks/KERAS_check_best_model_weights.h5\n",
      "Epoch 00029: saving model to .\\training_callbacks/KERAS_check_model_last.h5\n",
      "Epoch 00029: saving model to .\\training_callbacks/KERAS_check_model_last_weights.h5\n",
      "Epoch 00029: saving model to .\\training_callbacks/KERAS_check_model_epoch29.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "59261/59261 [==============================] - 1s - loss: 1.1160 - acc: 0.5977 - val_loss: 1.1140 - val_acc: 0.5922\n",
      "Epoch 31/100\n",
      "56320/59261 [===========================>..] - ETA: 0s - loss: 1.1126 - acc: 0.6006- ETA: 0s - loss: 1.1064 -\n",
      "***callbacks***\n",
      "saving losses to .\\training_callbacks\\losses.log\n",
      "Epoch 00030: val_loss improved from 1.11399 to 1.11120, saving model to .\\training_callbacks/KERAS_check_best_model.h5\n",
      "Epoch 00030: val_loss improved from 1.11399 to 1.11120, saving model to .\\training_callbacks/KERAS_check_best_model_weights.h5\n",
      "Epoch 00030: saving model to .\\training_callbacks/KERAS_check_model_last.h5\n",
      "Epoch 00030: saving model to .\\training_callbacks/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "59261/59261 [==============================] - 1s - loss: 1.1126 - acc: 0.6005 - val_loss: 1.1112 - val_acc: 0.5959\n",
      "Epoch 32/100\n",
      "58368/59261 [============================>.] - ETA: 0s - loss: 1.1087 - acc: 0.6030\n",
      "***callbacks***\n",
      "saving losses to .\\training_callbacks\\losses.log\n",
      "Epoch 00031: val_loss improved from 1.11120 to 1.10800, saving model to .\\training_callbacks/KERAS_check_best_model.h5\n",
      "Epoch 00031: val_loss improved from 1.11120 to 1.10800, saving model to .\\training_callbacks/KERAS_check_best_model_weights.h5\n",
      "Epoch 00031: saving model to .\\training_callbacks/KERAS_check_model_last.h5\n",
      "Epoch 00031: saving model to .\\training_callbacks/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "59261/59261 [==============================] - 1s - loss: 1.1095 - acc: 0.6029 - val_loss: 1.1080 - val_acc: 0.5978\n",
      "Epoch 33/100\n",
      "56320/59261 [===========================>..] - ETA: 0s - loss: 1.1064 - acc: 0.6039\n",
      "***callbacks***\n",
      "saving losses to .\\training_callbacks\\losses.log\n",
      "Epoch 00032: val_loss improved from 1.10800 to 1.10565, saving model to .\\training_callbacks/KERAS_check_best_model.h5\n",
      "Epoch 00032: val_loss improved from 1.10800 to 1.10565, saving model to .\\training_callbacks/KERAS_check_best_model_weights.h5\n",
      "Epoch 00032: saving model to .\\training_callbacks/KERAS_check_model_last.h5\n",
      "Epoch 00032: saving model to .\\training_callbacks/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "59261/59261 [==============================] - 1s - loss: 1.1062 - acc: 0.6046 - val_loss: 1.1057 - val_acc: 0.5996\n",
      "Epoch 34/100\n",
      "56320/59261 [===========================>..] - ETA: 0s - loss: 1.1036 - acc: 0.6061\n",
      "***callbacks***\n",
      "saving losses to .\\training_callbacks\\losses.log\n",
      "Epoch 00033: val_loss improved from 1.10565 to 1.10287, saving model to .\\training_callbacks/KERAS_check_best_model.h5\n",
      "Epoch 00033: val_loss improved from 1.10565 to 1.10287, saving model to .\\training_callbacks/KERAS_check_best_model_weights.h5\n",
      "Epoch 00033: saving model to .\\training_callbacks/KERAS_check_model_last.h5\n",
      "Epoch 00033: saving model to .\\training_callbacks/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59261/59261 [==============================] - 1s - loss: 1.1032 - acc: 0.6062 - val_loss: 1.1029 - val_acc: 0.6021\n",
      "Epoch 35/100\n",
      "56320/59261 [===========================>..] - ETA: 0s - loss: 1.1003 - acc: 0.6093\n",
      "***callbacks***\n",
      "saving losses to .\\training_callbacks\\losses.log\n",
      "Epoch 00034: val_loss improved from 1.10287 to 1.09995, saving model to .\\training_callbacks/KERAS_check_best_model.h5\n",
      "Epoch 00034: val_loss improved from 1.10287 to 1.09995, saving model to .\\training_callbacks/KERAS_check_best_model_weights.h5\n",
      "Epoch 00034: saving model to .\\training_callbacks/KERAS_check_model_last.h5\n",
      "Epoch 00034: saving model to .\\training_callbacks/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "59261/59261 [==============================] - 1s - loss: 1.1003 - acc: 0.6088 - val_loss: 1.0999 - val_acc: 0.6021\n",
      "Epoch 36/100\n",
      "56320/59261 [===========================>..] - ETA: 0s - loss: 1.0972 - acc: 0.6103\n",
      "***callbacks***\n",
      "saving losses to .\\training_callbacks\\losses.log\n",
      "Epoch 00035: val_loss improved from 1.09995 to 1.09738, saving model to .\\training_callbacks/KERAS_check_best_model.h5\n",
      "Epoch 00035: val_loss improved from 1.09995 to 1.09738, saving model to .\\training_callbacks/KERAS_check_best_model_weights.h5\n",
      "Epoch 00035: saving model to .\\training_callbacks/KERAS_check_model_last.h5\n",
      "Epoch 00035: saving model to .\\training_callbacks/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "59261/59261 [==============================] - 1s - loss: 1.0975 - acc: 0.6103 - val_loss: 1.0974 - val_acc: 0.6033\n",
      "Epoch 37/100\n",
      "56320/59261 [===========================>..] - ETA: 0s - loss: 1.0949 - acc: 0.6112\n",
      "***callbacks***\n",
      "saving losses to .\\training_callbacks\\losses.log\n",
      "Epoch 00036: val_loss improved from 1.09738 to 1.09493, saving model to .\\training_callbacks/KERAS_check_best_model.h5\n",
      "Epoch 00036: val_loss improved from 1.09738 to 1.09493, saving model to .\\training_callbacks/KERAS_check_best_model_weights.h5\n",
      "Epoch 00036: saving model to .\\training_callbacks/KERAS_check_model_last.h5\n",
      "Epoch 00036: saving model to .\\training_callbacks/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "59261/59261 [==============================] - 1s - loss: 1.0947 - acc: 0.6113 - val_loss: 1.0949 - val_acc: 0.6052\n",
      "Epoch 38/100\n",
      "56320/59261 [===========================>..] - ETA: 0s - loss: 1.0912 - acc: 0.6141\n",
      "***callbacks***\n",
      "saving losses to .\\training_callbacks\\losses.log\n",
      "Epoch 00037: val_loss improved from 1.09493 to 1.09231, saving model to .\\training_callbacks/KERAS_check_best_model.h5\n",
      "Epoch 00037: val_loss improved from 1.09493 to 1.09231, saving model to .\\training_callbacks/KERAS_check_best_model_weights.h5\n",
      "Epoch 00037: saving model to .\\training_callbacks/KERAS_check_model_last.h5\n",
      "Epoch 00037: saving model to .\\training_callbacks/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "59261/59261 [==============================] - 1s - loss: 1.0920 - acc: 0.6138 - val_loss: 1.0923 - val_acc: 0.6060\n",
      "Epoch 39/100\n",
      "56320/59261 [===========================>..] - ETA: 0s - loss: 1.0906 - acc: 0.6158\n",
      "***callbacks***\n",
      "saving losses to .\\training_callbacks\\losses.log\n",
      "Epoch 00038: val_loss improved from 1.09231 to 1.09050, saving model to .\\training_callbacks/KERAS_check_best_model.h5\n",
      "Epoch 00038: val_loss improved from 1.09231 to 1.09050, saving model to .\\training_callbacks/KERAS_check_best_model_weights.h5\n",
      "Epoch 00038: saving model to .\\training_callbacks/KERAS_check_model_last.h5\n",
      "Epoch 00038: saving model to .\\training_callbacks/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "59261/59261 [==============================] - 1s - loss: 1.0894 - acc: 0.6159 - val_loss: 1.0905 - val_acc: 0.6085\n",
      "Epoch 40/100\n",
      "56320/59261 [===========================>..] - ETA: 0s - loss: 1.0864 - acc: 0.6172\n",
      "***callbacks***\n",
      "saving losses to .\\training_callbacks\\losses.log\n",
      "Epoch 00039: val_loss improved from 1.09050 to 1.08752, saving model to .\\training_callbacks/KERAS_check_best_model.h5\n",
      "Epoch 00039: val_loss improved from 1.09050 to 1.08752, saving model to .\\training_callbacks/KERAS_check_best_model_weights.h5\n",
      "Epoch 00039: saving model to .\\training_callbacks/KERAS_check_model_last.h5\n",
      "Epoch 00039: saving model to .\\training_callbacks/KERAS_check_model_last_weights.h5\n",
      "Epoch 00039: saving model to .\\training_callbacks/KERAS_check_model_epoch39.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "59261/59261 [==============================] - 1s - loss: 1.0866 - acc: 0.6167 - val_loss: 1.0875 - val_acc: 0.6096\n",
      "Epoch 41/100\n",
      "56320/59261 [===========================>..] - ETA: 0s - loss: 1.0842 - acc: 0.6184\n",
      "***callbacks***\n",
      "saving losses to .\\training_callbacks\\losses.log\n",
      "Epoch 00040: val_loss improved from 1.08752 to 1.08590, saving model to .\\training_callbacks/KERAS_check_best_model.h5\n",
      "Epoch 00040: val_loss improved from 1.08752 to 1.08590, saving model to .\\training_callbacks/KERAS_check_best_model_weights.h5\n",
      "Epoch 00040: saving model to .\\training_callbacks/KERAS_check_model_last.h5\n",
      "Epoch 00040: saving model to .\\training_callbacks/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "59261/59261 [==============================] - 1s - loss: 1.0841 - acc: 0.6186 - val_loss: 1.0859 - val_acc: 0.6101\n",
      "Epoch 42/100\n",
      "56320/59261 [===========================>..] - ETA: 0s - loss: 1.0814 - acc: 0.6198\n",
      "***callbacks***\n",
      "saving losses to .\\training_callbacks\\losses.log\n",
      "Epoch 00041: val_loss improved from 1.08590 to 1.08319, saving model to .\\training_callbacks/KERAS_check_best_model.h5\n",
      "Epoch 00041: val_loss improved from 1.08590 to 1.08319, saving model to .\\training_callbacks/KERAS_check_best_model_weights.h5\n",
      "Epoch 00041: saving model to .\\training_callbacks/KERAS_check_model_last.h5\n",
      "Epoch 00041: saving model to .\\training_callbacks/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "59261/59261 [==============================] - 1s - loss: 1.0816 - acc: 0.6201 - val_loss: 1.0832 - val_acc: 0.6121\n",
      "Epoch 43/100\n",
      "56320/59261 [===========================>..] - ETA: 0s - loss: 1.0807 - acc: 0.6201\n",
      "***callbacks***\n",
      "saving losses to .\\training_callbacks\\losses.log\n",
      "Epoch 00042: val_loss improved from 1.08319 to 1.08079, saving model to .\\training_callbacks/KERAS_check_best_model.h5\n",
      "Epoch 00042: val_loss improved from 1.08319 to 1.08079, saving model to .\\training_callbacks/KERAS_check_best_model_weights.h5\n",
      "Epoch 00042: saving model to .\\training_callbacks/KERAS_check_model_last.h5\n",
      "Epoch 00042: saving model to .\\training_callbacks/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "59261/59261 [==============================] - 1s - loss: 1.0793 - acc: 0.6208 - val_loss: 1.0808 - val_acc: 0.6140\n",
      "Epoch 44/100\n",
      "56320/59261 [===========================>..] - ETA: 0s - loss: 1.0763 - acc: 0.6236- ETA: 0s - loss: 1.0719 -\n",
      "***callbacks***\n",
      "saving losses to .\\training_callbacks\\losses.log\n",
      "Epoch 00043: val_loss improved from 1.08079 to 1.07912, saving model to .\\training_callbacks/KERAS_check_best_model.h5\n",
      "Epoch 00043: val_loss improved from 1.08079 to 1.07912, saving model to .\\training_callbacks/KERAS_check_best_model_weights.h5\n",
      "Epoch 00043: saving model to .\\training_callbacks/KERAS_check_model_last.h5\n",
      "Epoch 00043: saving model to .\\training_callbacks/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "59261/59261 [==============================] - 1s - loss: 1.0770 - acc: 0.6231 - val_loss: 1.0791 - val_acc: 0.6148\n",
      "Epoch 45/100\n",
      "56320/59261 [===========================>..] - ETA: 0s - loss: 1.0755 - acc: 0.6236\n",
      "***callbacks***\n",
      "saving losses to .\\training_callbacks\\losses.log\n",
      "Epoch 00044: val_loss improved from 1.07912 to 1.07662, saving model to .\\training_callbacks/KERAS_check_best_model.h5\n",
      "Epoch 00044: val_loss improved from 1.07912 to 1.07662, saving model to .\\training_callbacks/KERAS_check_best_model_weights.h5\n",
      "Epoch 00044: saving model to .\\training_callbacks/KERAS_check_model_last.h5\n",
      "Epoch 00044: saving model to .\\training_callbacks/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "59261/59261 [==============================] - 1s - loss: 1.0746 - acc: 0.6239 - val_loss: 1.0766 - val_acc: 0.6155\n",
      "Epoch 46/100\n",
      "56320/59261 [===========================>..] - ETA: 0s - loss: 1.0731 - acc: 0.6255- ETA: 0s - loss: 1.0722 - acc: 0.625\n",
      "***callbacks***\n",
      "saving losses to .\\training_callbacks\\losses.log\n",
      "Epoch 00045: val_loss improved from 1.07662 to 1.07538, saving model to .\\training_callbacks/KERAS_check_best_model.h5\n",
      "Epoch 00045: val_loss improved from 1.07662 to 1.07538, saving model to .\\training_callbacks/KERAS_check_best_model_weights.h5\n",
      "Epoch 00045: saving model to .\\training_callbacks/KERAS_check_model_last.h5\n",
      "Epoch 00045: saving model to .\\training_callbacks/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59261/59261 [==============================] - 1s - loss: 1.0722 - acc: 0.6255 - val_loss: 1.0754 - val_acc: 0.6188\n",
      "Epoch 47/100\n",
      "56320/59261 [===========================>..] - ETA: 0s - loss: 1.0709 - acc: 0.6252\n",
      "***callbacks***\n",
      "saving losses to .\\training_callbacks\\losses.log\n",
      "Epoch 00046: val_loss improved from 1.07538 to 1.07270, saving model to .\\training_callbacks/KERAS_check_best_model.h5\n",
      "Epoch 00046: val_loss improved from 1.07538 to 1.07270, saving model to .\\training_callbacks/KERAS_check_best_model_weights.h5\n",
      "Epoch 00046: saving model to .\\training_callbacks/KERAS_check_model_last.h5\n",
      "Epoch 00046: saving model to .\\training_callbacks/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "59261/59261 [==============================] - 1s - loss: 1.0699 - acc: 0.6262 - val_loss: 1.0727 - val_acc: 0.6214\n",
      "Epoch 48/100\n",
      "56320/59261 [===========================>..] - ETA: 0s - loss: 1.0672 - acc: 0.6283\n",
      "***callbacks***\n",
      "saving losses to .\\training_callbacks\\losses.log\n",
      "Epoch 00047: val_loss improved from 1.07270 to 1.07060, saving model to .\\training_callbacks/KERAS_check_best_model.h5\n",
      "Epoch 00047: val_loss improved from 1.07270 to 1.07060, saving model to .\\training_callbacks/KERAS_check_best_model_weights.h5\n",
      "Epoch 00047: saving model to .\\training_callbacks/KERAS_check_model_last.h5\n",
      "Epoch 00047: saving model to .\\training_callbacks/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "59261/59261 [==============================] - 1s - loss: 1.0676 - acc: 0.6282 - val_loss: 1.0706 - val_acc: 0.6235\n",
      "Epoch 49/100\n",
      "56320/59261 [===========================>..] - ETA: 0s - loss: 1.0647 - acc: 0.6291\n",
      "***callbacks***\n",
      "saving losses to .\\training_callbacks\\losses.log\n",
      "Epoch 00048: val_loss improved from 1.07060 to 1.06824, saving model to .\\training_callbacks/KERAS_check_best_model.h5\n",
      "Epoch 00048: val_loss improved from 1.07060 to 1.06824, saving model to .\\training_callbacks/KERAS_check_best_model_weights.h5\n",
      "Epoch 00048: saving model to .\\training_callbacks/KERAS_check_model_last.h5\n",
      "Epoch 00048: saving model to .\\training_callbacks/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "59261/59261 [==============================] - 1s - loss: 1.0655 - acc: 0.6291 - val_loss: 1.0682 - val_acc: 0.6225\n",
      "Epoch 50/100\n",
      "56320/59261 [===========================>..] - ETA: 0s - loss: 1.0637 - acc: 0.6302\n",
      "***callbacks***\n",
      "saving losses to .\\training_callbacks\\losses.log\n",
      "Epoch 00049: val_loss improved from 1.06824 to 1.06741, saving model to .\\training_callbacks/KERAS_check_best_model.h5\n",
      "Epoch 00049: val_loss improved from 1.06824 to 1.06741, saving model to .\\training_callbacks/KERAS_check_best_model_weights.h5\n",
      "Epoch 00049: saving model to .\\training_callbacks/KERAS_check_model_last.h5\n",
      "Epoch 00049: saving model to .\\training_callbacks/KERAS_check_model_last_weights.h5\n",
      "Epoch 00049: saving model to .\\training_callbacks/KERAS_check_model_epoch49.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "59261/59261 [==============================] - 1s - loss: 1.0632 - acc: 0.6306 - val_loss: 1.0674 - val_acc: 0.6220\n",
      "Epoch 51/100\n",
      "58368/59261 [============================>.] - ETA: 0s - loss: 1.0608 - acc: 0.6323\n",
      "***callbacks***\n",
      "saving losses to .\\training_callbacks\\losses.log\n",
      "Epoch 00050: val_loss improved from 1.06741 to 1.06437, saving model to .\\training_callbacks/KERAS_check_best_model.h5\n",
      "Epoch 00050: val_loss improved from 1.06741 to 1.06437, saving model to .\\training_callbacks/KERAS_check_best_model_weights.h5\n",
      "Epoch 00050: saving model to .\\training_callbacks/KERAS_check_model_last.h5\n",
      "Epoch 00050: saving model to .\\training_callbacks/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "59261/59261 [==============================] - 1s - loss: 1.0611 - acc: 0.6323 - val_loss: 1.0644 - val_acc: 0.6253\n",
      "Epoch 52/100\n",
      "56320/59261 [===========================>..] - ETA: 0s - loss: 1.0600 - acc: 0.6326\n",
      "***callbacks***\n",
      "saving losses to .\\training_callbacks\\losses.log\n",
      "Epoch 00051: val_loss improved from 1.06437 to 1.06237, saving model to .\\training_callbacks/KERAS_check_best_model.h5\n",
      "Epoch 00051: val_loss improved from 1.06437 to 1.06237, saving model to .\\training_callbacks/KERAS_check_best_model_weights.h5\n",
      "Epoch 00051: saving model to .\\training_callbacks/KERAS_check_model_last.h5\n",
      "Epoch 00051: saving model to .\\training_callbacks/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "59261/59261 [==============================] - 1s - loss: 1.0588 - acc: 0.6332 - val_loss: 1.0624 - val_acc: 0.6265\n",
      "Epoch 53/100\n",
      "56320/59261 [===========================>..] - ETA: 0s - loss: 1.0562 - acc: 0.6338\n",
      "***callbacks***\n",
      "saving losses to .\\training_callbacks\\losses.log\n",
      "Epoch 00052: val_loss improved from 1.06237 to 1.06064, saving model to .\\training_callbacks/KERAS_check_best_model.h5\n",
      "Epoch 00052: val_loss improved from 1.06237 to 1.06064, saving model to .\\training_callbacks/KERAS_check_best_model_weights.h5\n",
      "Epoch 00052: saving model to .\\training_callbacks/KERAS_check_model_last.h5\n",
      "Epoch 00052: saving model to .\\training_callbacks/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "59261/59261 [==============================] - 1s - loss: 1.0565 - acc: 0.6342 - val_loss: 1.0606 - val_acc: 0.6289\n",
      "Epoch 54/100\n",
      "56320/59261 [===========================>..] - ETA: 0s - loss: 1.0542 - acc: 0.6350\n",
      "***callbacks***\n",
      "saving losses to .\\training_callbacks\\losses.log\n",
      "Epoch 00053: val_loss improved from 1.06064 to 1.05854, saving model to .\\training_callbacks/KERAS_check_best_model.h5\n",
      "Epoch 00053: val_loss improved from 1.06064 to 1.05854, saving model to .\\training_callbacks/KERAS_check_best_model_weights.h5\n",
      "Epoch 00053: saving model to .\\training_callbacks/KERAS_check_model_last.h5\n",
      "Epoch 00053: saving model to .\\training_callbacks/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "59261/59261 [==============================] - 1s - loss: 1.0546 - acc: 0.6350 - val_loss: 1.0585 - val_acc: 0.6292\n",
      "Epoch 55/100\n",
      "56320/59261 [===========================>..] - ETA: 0s - loss: 1.0521 - acc: 0.6365\n",
      "***callbacks***\n",
      "saving losses to .\\training_callbacks\\losses.log\n",
      "Epoch 00054: val_loss improved from 1.05854 to 1.05667, saving model to .\\training_callbacks/KERAS_check_best_model.h5\n",
      "Epoch 00054: val_loss improved from 1.05854 to 1.05667, saving model to .\\training_callbacks/KERAS_check_best_model_weights.h5\n",
      "Epoch 00054: saving model to .\\training_callbacks/KERAS_check_model_last.h5\n",
      "Epoch 00054: saving model to .\\training_callbacks/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "59261/59261 [==============================] - 1s - loss: 1.0524 - acc: 0.6362 - val_loss: 1.0567 - val_acc: 0.6316\n",
      "Epoch 56/100\n",
      "56320/59261 [===========================>..] - ETA: 0s - loss: 1.0497 - acc: 0.6391\n",
      "***callbacks***\n",
      "saving losses to .\\training_callbacks\\losses.log\n",
      "Epoch 00055: val_loss improved from 1.05667 to 1.05525, saving model to .\\training_callbacks/KERAS_check_best_model.h5\n",
      "Epoch 00055: val_loss improved from 1.05667 to 1.05525, saving model to .\\training_callbacks/KERAS_check_best_model_weights.h5\n",
      "Epoch 00055: saving model to .\\training_callbacks/KERAS_check_model_last.h5\n",
      "Epoch 00055: saving model to .\\training_callbacks/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "59261/59261 [==============================] - 1s - loss: 1.0503 - acc: 0.6382 - val_loss: 1.0552 - val_acc: 0.6336\n",
      "Epoch 57/100\n",
      "56320/59261 [===========================>..] - ETA: 0s - loss: 1.0497 - acc: 0.6389\n",
      "***callbacks***\n",
      "saving losses to .\\training_callbacks\\losses.log\n",
      "Epoch 00056: val_loss improved from 1.05525 to 1.05255, saving model to .\\training_callbacks/KERAS_check_best_model.h5\n",
      "Epoch 00056: val_loss improved from 1.05525 to 1.05255, saving model to .\\training_callbacks/KERAS_check_best_model_weights.h5\n",
      "Epoch 00056: saving model to .\\training_callbacks/KERAS_check_model_last.h5\n",
      "Epoch 00056: saving model to .\\training_callbacks/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "59261/59261 [==============================] - 1s - loss: 1.0479 - acc: 0.6393 - val_loss: 1.0525 - val_acc: 0.6342\n",
      "Epoch 58/100\n",
      "56320/59261 [===========================>..] - ETA: 0s - loss: 1.0445 - acc: 0.6399\n",
      "***callbacks***\n",
      "saving losses to .\\training_callbacks\\losses.log\n",
      "Epoch 00057: val_loss improved from 1.05255 to 1.05090, saving model to .\\training_callbacks/KERAS_check_best_model.h5\n",
      "Epoch 00057: val_loss improved from 1.05255 to 1.05090, saving model to .\\training_callbacks/KERAS_check_best_model_weights.h5\n",
      "Epoch 00057: saving model to .\\training_callbacks/KERAS_check_model_last.h5\n",
      "Epoch 00057: saving model to .\\training_callbacks/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59261/59261 [==============================] - 1s - loss: 1.0462 - acc: 0.6400 - val_loss: 1.0509 - val_acc: 0.6351\n",
      "Epoch 59/100\n",
      "56320/59261 [===========================>..] - ETA: 0s - loss: 1.0431 - acc: 0.6419\n",
      "***callbacks***\n",
      "saving losses to .\\training_callbacks\\losses.log\n",
      "Epoch 00058: val_loss improved from 1.05090 to 1.04853, saving model to .\\training_callbacks/KERAS_check_best_model.h5\n",
      "Epoch 00058: val_loss improved from 1.05090 to 1.04853, saving model to .\\training_callbacks/KERAS_check_best_model_weights.h5\n",
      "Epoch 00058: saving model to .\\training_callbacks/KERAS_check_model_last.h5\n",
      "Epoch 00058: saving model to .\\training_callbacks/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "59261/59261 [==============================] - 1s - loss: 1.0439 - acc: 0.6411 - val_loss: 1.0485 - val_acc: 0.6353\n",
      "Epoch 60/100\n",
      "56320/59261 [===========================>..] - ETA: 0s - loss: 1.0421 - acc: 0.6433\n",
      "***callbacks***\n",
      "saving losses to .\\training_callbacks\\losses.log\n",
      "Epoch 00059: val_loss improved from 1.04853 to 1.04636, saving model to .\\training_callbacks/KERAS_check_best_model.h5\n",
      "Epoch 00059: val_loss improved from 1.04853 to 1.04636, saving model to .\\training_callbacks/KERAS_check_best_model_weights.h5\n",
      "Epoch 00059: saving model to .\\training_callbacks/KERAS_check_model_last.h5\n",
      "Epoch 00059: saving model to .\\training_callbacks/KERAS_check_model_last_weights.h5\n",
      "Epoch 00059: saving model to .\\training_callbacks/KERAS_check_model_epoch59.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "59261/59261 [==============================] - 1s - loss: 1.0420 - acc: 0.6429 - val_loss: 1.0464 - val_acc: 0.6373\n",
      "Epoch 61/100\n",
      "56320/59261 [===========================>..] - ETA: 0s - loss: 1.0393 - acc: 0.6439\n",
      "***callbacks***\n",
      "saving losses to .\\training_callbacks\\losses.log\n",
      "Epoch 00060: val_loss improved from 1.04636 to 1.04576, saving model to .\\training_callbacks/KERAS_check_best_model.h5\n",
      "Epoch 00060: val_loss improved from 1.04636 to 1.04576, saving model to .\\training_callbacks/KERAS_check_best_model_weights.h5\n",
      "Epoch 00060: saving model to .\\training_callbacks/KERAS_check_model_last.h5\n",
      "Epoch 00060: saving model to .\\training_callbacks/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "59261/59261 [==============================] - 1s - loss: 1.0399 - acc: 0.6439 - val_loss: 1.0458 - val_acc: 0.6376\n",
      "Epoch 62/100\n",
      "56320/59261 [===========================>..] - ETA: 0s - loss: 1.0380 - acc: 0.6450- ETA: 0s - loss: 1.0454 -\n",
      "***callbacks***\n",
      "saving losses to .\\training_callbacks\\losses.log\n",
      "Epoch 00061: val_loss improved from 1.04576 to 1.04294, saving model to .\\training_callbacks/KERAS_check_best_model.h5\n",
      "Epoch 00061: val_loss improved from 1.04576 to 1.04294, saving model to .\\training_callbacks/KERAS_check_best_model_weights.h5\n",
      "Epoch 00061: saving model to .\\training_callbacks/KERAS_check_model_last.h5\n",
      "Epoch 00061: saving model to .\\training_callbacks/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "59261/59261 [==============================] - 1s - loss: 1.0379 - acc: 0.6451 - val_loss: 1.0429 - val_acc: 0.6398\n",
      "Epoch 63/100\n",
      "56320/59261 [===========================>..] - ETA: 0s - loss: 1.0378 - acc: 0.6455\n",
      "***callbacks***\n",
      "saving losses to .\\training_callbacks\\losses.log\n",
      "Epoch 00062: val_loss improved from 1.04294 to 1.04190, saving model to .\\training_callbacks/KERAS_check_best_model.h5\n",
      "Epoch 00062: val_loss improved from 1.04294 to 1.04190, saving model to .\\training_callbacks/KERAS_check_best_model_weights.h5\n",
      "Epoch 00062: saving model to .\\training_callbacks/KERAS_check_model_last.h5\n",
      "Epoch 00062: saving model to .\\training_callbacks/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "59261/59261 [==============================] - 1s - loss: 1.0359 - acc: 0.6465 - val_loss: 1.0419 - val_acc: 0.6406\n",
      "Epoch 64/100\n",
      "56320/59261 [===========================>..] - ETA: 0s - loss: 1.0347 - acc: 0.6463\n",
      "***callbacks***\n",
      "saving losses to .\\training_callbacks\\losses.log\n",
      "Epoch 00063: val_loss improved from 1.04190 to 1.03857, saving model to .\\training_callbacks/KERAS_check_best_model.h5\n",
      "Epoch 00063: val_loss improved from 1.04190 to 1.03857, saving model to .\\training_callbacks/KERAS_check_best_model_weights.h5\n",
      "Epoch 00063: saving model to .\\training_callbacks/KERAS_check_model_last.h5\n",
      "Epoch 00063: saving model to .\\training_callbacks/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "59261/59261 [==============================] - 1s - loss: 1.0340 - acc: 0.6468 - val_loss: 1.0386 - val_acc: 0.6417\n",
      "Epoch 65/100\n",
      "58368/59261 [============================>.] - ETA: 0s - loss: 1.0322 - acc: 0.6480\n",
      "***callbacks***\n",
      "saving losses to .\\training_callbacks\\losses.log\n",
      "Epoch 00064: val_loss improved from 1.03857 to 1.03712, saving model to .\\training_callbacks/KERAS_check_best_model.h5\n",
      "Epoch 00064: val_loss improved from 1.03857 to 1.03712, saving model to .\\training_callbacks/KERAS_check_best_model_weights.h5\n",
      "Epoch 00064: saving model to .\\training_callbacks/KERAS_check_model_last.h5\n",
      "Epoch 00064: saving model to .\\training_callbacks/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "59261/59261 [==============================] - 1s - loss: 1.0314 - acc: 0.6481 - val_loss: 1.0371 - val_acc: 0.6439\n",
      "Epoch 66/100\n",
      "56320/59261 [===========================>..] - ETA: 0s - loss: 1.0312 - acc: 0.6477\n",
      "***callbacks***\n",
      "saving losses to .\\training_callbacks\\losses.log\n",
      "Epoch 00065: val_loss improved from 1.03712 to 1.03608, saving model to .\\training_callbacks/KERAS_check_best_model.h5\n",
      "Epoch 00065: val_loss improved from 1.03712 to 1.03608, saving model to .\\training_callbacks/KERAS_check_best_model_weights.h5\n",
      "Epoch 00065: saving model to .\\training_callbacks/KERAS_check_model_last.h5\n",
      "Epoch 00065: saving model to .\\training_callbacks/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "59261/59261 [==============================] - 1s - loss: 1.0297 - acc: 0.6486 - val_loss: 1.0361 - val_acc: 0.6448\n",
      "Epoch 67/100\n",
      "56320/59261 [===========================>..] - ETA: 0s - loss: 1.0275 - acc: 0.6502\n",
      "***callbacks***\n",
      "saving losses to .\\training_callbacks\\losses.log\n",
      "Epoch 00066: val_loss improved from 1.03608 to 1.03349, saving model to .\\training_callbacks/KERAS_check_best_model.h5\n",
      "Epoch 00066: val_loss improved from 1.03608 to 1.03349, saving model to .\\training_callbacks/KERAS_check_best_model_weights.h5\n",
      "Epoch 00066: saving model to .\\training_callbacks/KERAS_check_model_last.h5\n",
      "Epoch 00066: saving model to .\\training_callbacks/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "59261/59261 [==============================] - 1s - loss: 1.0277 - acc: 0.6501 - val_loss: 1.0335 - val_acc: 0.6462\n",
      "Epoch 68/100\n",
      "56320/59261 [===========================>..] - ETA: 0s - loss: 1.0252 - acc: 0.6511- ETA: 0s - loss: 1.0304 - acc\n",
      "***callbacks***\n",
      "saving losses to .\\training_callbacks\\losses.log\n",
      "Epoch 00067: val_loss improved from 1.03349 to 1.03161, saving model to .\\training_callbacks/KERAS_check_best_model.h5\n",
      "Epoch 00067: val_loss improved from 1.03349 to 1.03161, saving model to .\\training_callbacks/KERAS_check_best_model_weights.h5\n",
      "Epoch 00067: saving model to .\\training_callbacks/KERAS_check_model_last.h5\n",
      "Epoch 00067: saving model to .\\training_callbacks/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "59261/59261 [==============================] - 1s - loss: 1.0256 - acc: 0.6511 - val_loss: 1.0316 - val_acc: 0.6467\n",
      "Epoch 69/100\n",
      "56320/59261 [===========================>..] - ETA: 0s - loss: 1.0231 - acc: 0.6515\n",
      "***callbacks***\n",
      "saving losses to .\\training_callbacks\\losses.log\n",
      "Epoch 00068: val_loss improved from 1.03161 to 1.03029, saving model to .\\training_callbacks/KERAS_check_best_model.h5\n",
      "Epoch 00068: val_loss improved from 1.03161 to 1.03029, saving model to .\\training_callbacks/KERAS_check_best_model_weights.h5\n",
      "Epoch 00068: saving model to .\\training_callbacks/KERAS_check_model_last.h5\n",
      "Epoch 00068: saving model to .\\training_callbacks/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "59261/59261 [==============================] - 1s - loss: 1.0237 - acc: 0.6511 - val_loss: 1.0303 - val_acc: 0.6472\n",
      "Epoch 70/100\n",
      "56320/59261 [===========================>..] - ETA: 0s - loss: 1.0218 - acc: 0.6521\n",
      "***callbacks***\n",
      "saving losses to .\\training_callbacks\\losses.log\n",
      "Epoch 00069: val_loss improved from 1.03029 to 1.02764, saving model to .\\training_callbacks/KERAS_check_best_model.h5\n",
      "Epoch 00069: val_loss improved from 1.03029 to 1.02764, saving model to .\\training_callbacks/KERAS_check_best_model_weights.h5\n",
      "Epoch 00069: saving model to .\\training_callbacks/KERAS_check_model_last.h5\n",
      "Epoch 00069: saving model to .\\training_callbacks/KERAS_check_model_last_weights.h5\n",
      "Epoch 00069: saving model to .\\training_callbacks/KERAS_check_model_epoch69.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59261/59261 [==============================] - 1s - loss: 1.0215 - acc: 0.6525 - val_loss: 1.0276 - val_acc: 0.6491\n",
      "Epoch 71/100\n",
      "56320/59261 [===========================>..] - ETA: 0s - loss: 1.0212 - acc: 0.6532\n",
      "***callbacks***\n",
      "saving losses to .\\training_callbacks\\losses.log\n",
      "Epoch 00070: val_loss improved from 1.02764 to 1.02604, saving model to .\\training_callbacks/KERAS_check_best_model.h5\n",
      "Epoch 00070: val_loss improved from 1.02764 to 1.02604, saving model to .\\training_callbacks/KERAS_check_best_model_weights.h5\n",
      "Epoch 00070: saving model to .\\training_callbacks/KERAS_check_model_last.h5\n",
      "Epoch 00070: saving model to .\\training_callbacks/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "59261/59261 [==============================] - 1s - loss: 1.0196 - acc: 0.6538 - val_loss: 1.0260 - val_acc: 0.6496\n",
      "Epoch 72/100\n",
      "56320/59261 [===========================>..] - ETA: 0s - loss: 1.0169 - acc: 0.6545\n",
      "***callbacks***\n",
      "saving losses to .\\training_callbacks\\losses.log\n",
      "Epoch 00071: val_loss improved from 1.02604 to 1.02362, saving model to .\\training_callbacks/KERAS_check_best_model.h5\n",
      "Epoch 00071: val_loss improved from 1.02604 to 1.02362, saving model to .\\training_callbacks/KERAS_check_best_model_weights.h5\n",
      "Epoch 00071: saving model to .\\training_callbacks/KERAS_check_model_last.h5\n",
      "Epoch 00071: saving model to .\\training_callbacks/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "59261/59261 [==============================] - 1s - loss: 1.0177 - acc: 0.6542 - val_loss: 1.0236 - val_acc: 0.6522\n",
      "Epoch 73/100\n",
      "58368/59261 [============================>.] - ETA: 0s - loss: 1.0158 - acc: 0.6563- ETA: 0s - loss: 1.0117 - a\n",
      "***callbacks***\n",
      "saving losses to .\\training_callbacks\\losses.log\n",
      "Epoch 00072: val_loss improved from 1.02362 to 1.02198, saving model to .\\training_callbacks/KERAS_check_best_model.h5\n",
      "Epoch 00072: val_loss improved from 1.02362 to 1.02198, saving model to .\\training_callbacks/KERAS_check_best_model_weights.h5\n",
      "Epoch 00072: saving model to .\\training_callbacks/KERAS_check_model_last.h5\n",
      "Epoch 00072: saving model to .\\training_callbacks/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "59261/59261 [==============================] - 1s - loss: 1.0157 - acc: 0.6562 - val_loss: 1.0220 - val_acc: 0.6515\n",
      "Epoch 74/100\n",
      "58368/59261 [============================>.] - ETA: 0s - loss: 1.0136 - acc: 0.6567\n",
      "***callbacks***\n",
      "saving losses to .\\training_callbacks\\losses.log\n",
      "Epoch 00073: val_loss improved from 1.02198 to 1.02008, saving model to .\\training_callbacks/KERAS_check_best_model.h5\n",
      "Epoch 00073: val_loss improved from 1.02198 to 1.02008, saving model to .\\training_callbacks/KERAS_check_best_model_weights.h5\n",
      "Epoch 00073: saving model to .\\training_callbacks/KERAS_check_model_last.h5\n",
      "Epoch 00073: saving model to .\\training_callbacks/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "59261/59261 [==============================] - 1s - loss: 1.0137 - acc: 0.6567 - val_loss: 1.0201 - val_acc: 0.6531\n",
      "Epoch 75/100\n",
      "56320/59261 [===========================>..] - ETA: 0s - loss: 1.0118 - acc: 0.6572\n",
      "***callbacks***\n",
      "saving losses to .\\training_callbacks\\losses.log\n",
      "Epoch 00074: val_loss improved from 1.02008 to 1.01775, saving model to .\\training_callbacks/KERAS_check_best_model.h5\n",
      "Epoch 00074: val_loss improved from 1.02008 to 1.01775, saving model to .\\training_callbacks/KERAS_check_best_model_weights.h5\n",
      "Epoch 00074: saving model to .\\training_callbacks/KERAS_check_model_last.h5\n",
      "Epoch 00074: saving model to .\\training_callbacks/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "59261/59261 [==============================] - 1s - loss: 1.0116 - acc: 0.6574 - val_loss: 1.0178 - val_acc: 0.6551\n",
      "Epoch 76/100\n",
      "56320/59261 [===========================>..] - ETA: 0s - loss: 1.0094 - acc: 0.6582\n",
      "***callbacks***\n",
      "saving losses to .\\training_callbacks\\losses.log\n",
      "Epoch 00075: val_loss improved from 1.01775 to 1.01740, saving model to .\\training_callbacks/KERAS_check_best_model.h5\n",
      "Epoch 00075: val_loss improved from 1.01775 to 1.01740, saving model to .\\training_callbacks/KERAS_check_best_model_weights.h5\n",
      "Epoch 00075: saving model to .\\training_callbacks/KERAS_check_model_last.h5\n",
      "Epoch 00075: saving model to .\\training_callbacks/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "59261/59261 [==============================] - 1s - loss: 1.0099 - acc: 0.6583 - val_loss: 1.0174 - val_acc: 0.6547\n",
      "Epoch 77/100\n",
      "56320/59261 [===========================>..] - ETA: 0s - loss: 1.0085 - acc: 0.6595\n",
      "***callbacks***\n",
      "saving losses to .\\training_callbacks\\losses.log\n",
      "Epoch 00076: val_loss improved from 1.01740 to 1.01599, saving model to .\\training_callbacks/KERAS_check_best_model.h5\n",
      "Epoch 00076: val_loss improved from 1.01740 to 1.01599, saving model to .\\training_callbacks/KERAS_check_best_model_weights.h5\n",
      "Epoch 00076: saving model to .\\training_callbacks/KERAS_check_model_last.h5\n",
      "Epoch 00076: saving model to .\\training_callbacks/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "59261/59261 [==============================] - 1s - loss: 1.0082 - acc: 0.6596 - val_loss: 1.0160 - val_acc: 0.6554\n",
      "Epoch 78/100\n",
      "56320/59261 [===========================>..] - ETA: 0s - loss: 1.0067 - acc: 0.6606\n",
      "***callbacks***\n",
      "saving losses to .\\training_callbacks\\losses.log\n",
      "Epoch 00077: val_loss improved from 1.01599 to 1.01246, saving model to .\\training_callbacks/KERAS_check_best_model.h5\n",
      "Epoch 00077: val_loss improved from 1.01599 to 1.01246, saving model to .\\training_callbacks/KERAS_check_best_model_weights.h5\n",
      "Epoch 00077: saving model to .\\training_callbacks/KERAS_check_model_last.h5\n",
      "Epoch 00077: saving model to .\\training_callbacks/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "59261/59261 [==============================] - 1s - loss: 1.0061 - acc: 0.6609 - val_loss: 1.0125 - val_acc: 0.6575\n",
      "Epoch 79/100\n",
      "56320/59261 [===========================>..] - ETA: 0s - loss: 1.0047 - acc: 0.6617\n",
      "***callbacks***\n",
      "saving losses to .\\training_callbacks\\losses.log\n",
      "Epoch 00078: val_loss improved from 1.01246 to 1.01003, saving model to .\\training_callbacks/KERAS_check_best_model.h5\n",
      "Epoch 00078: val_loss improved from 1.01246 to 1.01003, saving model to .\\training_callbacks/KERAS_check_best_model_weights.h5\n",
      "Epoch 00078: saving model to .\\training_callbacks/KERAS_check_model_last.h5\n",
      "Epoch 00078: saving model to .\\training_callbacks/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "59261/59261 [==============================] - 1s - loss: 1.0041 - acc: 0.6622 - val_loss: 1.0100 - val_acc: 0.6592\n",
      "Epoch 80/100\n",
      "56320/59261 [===========================>..] - ETA: 0s - loss: 1.0032 - acc: 0.6621- ETA: 0s - loss: 1.0032 - acc: 0.6\n",
      "***callbacks***\n",
      "saving losses to .\\training_callbacks\\losses.log\n",
      "Epoch 00079: val_loss improved from 1.01003 to 1.00976, saving model to .\\training_callbacks/KERAS_check_best_model.h5\n",
      "Epoch 00079: val_loss improved from 1.01003 to 1.00976, saving model to .\\training_callbacks/KERAS_check_best_model_weights.h5\n",
      "Epoch 00079: saving model to .\\training_callbacks/KERAS_check_model_last.h5\n",
      "Epoch 00079: saving model to .\\training_callbacks/KERAS_check_model_last_weights.h5\n",
      "Epoch 00079: saving model to .\\training_callbacks/KERAS_check_model_epoch79.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "59261/59261 [==============================] - 1s - loss: 1.0022 - acc: 0.6623 - val_loss: 1.0098 - val_acc: 0.6588\n",
      "Epoch 81/100\n",
      "56320/59261 [===========================>..] - ETA: 0s - loss: 1.0019 - acc: 0.6633\n",
      "***callbacks***\n",
      "saving losses to .\\training_callbacks\\losses.log\n",
      "Epoch 00080: val_loss improved from 1.00976 to 1.00640, saving model to .\\training_callbacks/KERAS_check_best_model.h5\n",
      "Epoch 00080: val_loss improved from 1.00976 to 1.00640, saving model to .\\training_callbacks/KERAS_check_best_model_weights.h5\n",
      "Epoch 00080: saving model to .\\training_callbacks/KERAS_check_model_last.h5\n",
      "Epoch 00080: saving model to .\\training_callbacks/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "59261/59261 [==============================] - 1s - loss: 1.0006 - acc: 0.6633 - val_loss: 1.0064 - val_acc: 0.6618\n",
      "Epoch 82/100\n",
      "56320/59261 [===========================>..] - ETA: 0s - loss: 0.9997 - acc: 0.6643\n",
      "***callbacks***\n",
      "saving losses to .\\training_callbacks\\losses.log\n",
      "Epoch 00081: val_loss improved from 1.00640 to 1.00476, saving model to .\\training_callbacks/KERAS_check_best_model.h5\n",
      "Epoch 00081: val_loss improved from 1.00640 to 1.00476, saving model to .\\training_callbacks/KERAS_check_best_model_weights.h5\n",
      "Epoch 00081: saving model to .\\training_callbacks/KERAS_check_model_last.h5\n",
      "Epoch 00081: saving model to .\\training_callbacks/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59261/59261 [==============================] - 1s - loss: 0.9981 - acc: 0.6647 - val_loss: 1.0048 - val_acc: 0.6625\n",
      "Epoch 83/100\n",
      "56320/59261 [===========================>..] - ETA: 0s - loss: 0.9965 - acc: 0.6648\n",
      "***callbacks***\n",
      "saving losses to .\\training_callbacks\\losses.log\n",
      "Epoch 00082: val_loss improved from 1.00476 to 1.00308, saving model to .\\training_callbacks/KERAS_check_best_model.h5\n",
      "Epoch 00082: val_loss improved from 1.00476 to 1.00308, saving model to .\\training_callbacks/KERAS_check_best_model_weights.h5\n",
      "Epoch 00082: saving model to .\\training_callbacks/KERAS_check_model_last.h5\n",
      "Epoch 00082: saving model to .\\training_callbacks/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "59261/59261 [==============================] - 1s - loss: 0.9966 - acc: 0.6647 - val_loss: 1.0031 - val_acc: 0.6618\n",
      "Epoch 84/100\n",
      "56320/59261 [===========================>..] - ETA: 0s - loss: 0.9918 - acc: 0.6670\n",
      "***callbacks***\n",
      "saving losses to .\\training_callbacks\\losses.log\n",
      "Epoch 00083: val_loss improved from 1.00308 to 1.00101, saving model to .\\training_callbacks/KERAS_check_best_model.h5\n",
      "Epoch 00083: val_loss improved from 1.00308 to 1.00101, saving model to .\\training_callbacks/KERAS_check_best_model_weights.h5\n",
      "Epoch 00083: saving model to .\\training_callbacks/KERAS_check_model_last.h5\n",
      "Epoch 00083: saving model to .\\training_callbacks/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "59261/59261 [==============================] - 1s - loss: 0.9941 - acc: 0.6662 - val_loss: 1.0010 - val_acc: 0.6621\n",
      "Epoch 85/100\n",
      "56320/59261 [===========================>..] - ETA: 0s - loss: 0.9933 - acc: 0.6663\n",
      "***callbacks***\n",
      "saving losses to .\\training_callbacks\\losses.log\n",
      "Epoch 00084: val_loss improved from 1.00101 to 0.99884, saving model to .\\training_callbacks/KERAS_check_best_model.h5\n",
      "Epoch 00084: val_loss improved from 1.00101 to 0.99884, saving model to .\\training_callbacks/KERAS_check_best_model_weights.h5\n",
      "Epoch 00084: saving model to .\\training_callbacks/KERAS_check_model_last.h5\n",
      "Epoch 00084: saving model to .\\training_callbacks/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "59261/59261 [==============================] - 1s - loss: 0.9923 - acc: 0.6671 - val_loss: 0.9988 - val_acc: 0.6653\n",
      "Epoch 86/100\n",
      "56320/59261 [===========================>..] - ETA: 0s - loss: 0.9894 - acc: 0.6677\n",
      "***callbacks***\n",
      "saving losses to .\\training_callbacks\\losses.log\n",
      "Epoch 00085: val_loss improved from 0.99884 to 0.99787, saving model to .\\training_callbacks/KERAS_check_best_model.h5\n",
      "Epoch 00085: val_loss improved from 0.99884 to 0.99787, saving model to .\\training_callbacks/KERAS_check_best_model_weights.h5\n",
      "Epoch 00085: saving model to .\\training_callbacks/KERAS_check_model_last.h5\n",
      "Epoch 00085: saving model to .\\training_callbacks/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "59261/59261 [==============================] - 1s - loss: 0.9899 - acc: 0.6679 - val_loss: 0.9979 - val_acc: 0.6645\n",
      "Epoch 87/100\n",
      "56320/59261 [===========================>..] - ETA: 0s - loss: 0.9890 - acc: 0.6686\n",
      "***callbacks***\n",
      "saving losses to .\\training_callbacks\\losses.log\n",
      "Epoch 00086: val_loss improved from 0.99787 to 0.99455, saving model to .\\training_callbacks/KERAS_check_best_model.h5\n",
      "Epoch 00086: val_loss improved from 0.99787 to 0.99455, saving model to .\\training_callbacks/KERAS_check_best_model_weights.h5\n",
      "Epoch 00086: saving model to .\\training_callbacks/KERAS_check_model_last.h5\n",
      "Epoch 00086: saving model to .\\training_callbacks/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "59261/59261 [==============================] - 1s - loss: 0.9883 - acc: 0.6687 - val_loss: 0.9945 - val_acc: 0.6666\n",
      "Epoch 88/100\n",
      "56320/59261 [===========================>..] - ETA: 0s - loss: 0.9887 - acc: 0.6683\n",
      "***callbacks***\n",
      "saving losses to .\\training_callbacks\\losses.log\n",
      "Epoch 00087: val_loss improved from 0.99455 to 0.99406, saving model to .\\training_callbacks/KERAS_check_best_model.h5\n",
      "Epoch 00087: val_loss improved from 0.99455 to 0.99406, saving model to .\\training_callbacks/KERAS_check_best_model_weights.h5\n",
      "Epoch 00087: saving model to .\\training_callbacks/KERAS_check_model_last.h5\n",
      "Epoch 00087: saving model to .\\training_callbacks/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "59261/59261 [==============================] - 1s - loss: 0.9865 - acc: 0.6690 - val_loss: 0.9941 - val_acc: 0.6660\n",
      "Epoch 89/100\n",
      "56320/59261 [===========================>..] - ETA: 0s - loss: 0.9826 - acc: 0.6715\n",
      "***callbacks***\n",
      "saving losses to .\\training_callbacks\\losses.log\n",
      "Epoch 00088: val_loss improved from 0.99406 to 0.99128, saving model to .\\training_callbacks/KERAS_check_best_model.h5\n",
      "Epoch 00088: val_loss improved from 0.99406 to 0.99128, saving model to .\\training_callbacks/KERAS_check_best_model_weights.h5\n",
      "Epoch 00088: saving model to .\\training_callbacks/KERAS_check_model_last.h5\n",
      "Epoch 00088: saving model to .\\training_callbacks/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "59261/59261 [==============================] - 1s - loss: 0.9844 - acc: 0.6708 - val_loss: 0.9913 - val_acc: 0.6681\n",
      "Epoch 90/100\n",
      "56320/59261 [===========================>..] - ETA: 0s - loss: 0.9836 - acc: 0.6715\n",
      "***callbacks***\n",
      "saving losses to .\\training_callbacks\\losses.log\n",
      "Epoch 00089: val_loss improved from 0.99128 to 0.98818, saving model to .\\training_callbacks/KERAS_check_best_model.h5\n",
      "Epoch 00089: val_loss improved from 0.99128 to 0.98818, saving model to .\\training_callbacks/KERAS_check_best_model_weights.h5\n",
      "Epoch 00089: saving model to .\\training_callbacks/KERAS_check_model_last.h5\n",
      "Epoch 00089: saving model to .\\training_callbacks/KERAS_check_model_last_weights.h5\n",
      "Epoch 00089: saving model to .\\training_callbacks/KERAS_check_model_epoch89.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "59261/59261 [==============================] - 1s - loss: 0.9828 - acc: 0.6712 - val_loss: 0.9882 - val_acc: 0.6680\n",
      "Epoch 91/100\n",
      "56320/59261 [===========================>..] - ETA: 0s - loss: 0.9822 - acc: 0.6720\n",
      "***callbacks***\n",
      "saving losses to .\\training_callbacks\\losses.log\n",
      "Epoch 00090: val_loss improved from 0.98818 to 0.98661, saving model to .\\training_callbacks/KERAS_check_best_model.h5\n",
      "Epoch 00090: val_loss improved from 0.98818 to 0.98661, saving model to .\\training_callbacks/KERAS_check_best_model_weights.h5\n",
      "Epoch 00090: saving model to .\\training_callbacks/KERAS_check_model_last.h5\n",
      "Epoch 00090: saving model to .\\training_callbacks/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "59261/59261 [==============================] - 1s - loss: 0.9808 - acc: 0.6725 - val_loss: 0.9866 - val_acc: 0.6698\n",
      "Epoch 92/100\n",
      "56320/59261 [===========================>..] - ETA: 0s - loss: 0.9795 - acc: 0.6739\n",
      "***callbacks***\n",
      "saving losses to .\\training_callbacks\\losses.log\n",
      "Epoch 00091: val_loss improved from 0.98661 to 0.98479, saving model to .\\training_callbacks/KERAS_check_best_model.h5\n",
      "Epoch 00091: val_loss improved from 0.98661 to 0.98479, saving model to .\\training_callbacks/KERAS_check_best_model_weights.h5\n",
      "Epoch 00091: saving model to .\\training_callbacks/KERAS_check_model_last.h5\n",
      "Epoch 00091: saving model to .\\training_callbacks/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "59261/59261 [==============================] - 1s - loss: 0.9787 - acc: 0.6743 - val_loss: 0.9848 - val_acc: 0.6702\n",
      "Epoch 93/100\n",
      "56320/59261 [===========================>..] - ETA: 0s - loss: 0.9770 - acc: 0.6743\n",
      "***callbacks***\n",
      "saving losses to .\\training_callbacks\\losses.log\n",
      "Epoch 00092: val_loss improved from 0.98479 to 0.98331, saving model to .\\training_callbacks/KERAS_check_best_model.h5\n",
      "Epoch 00092: val_loss improved from 0.98479 to 0.98331, saving model to .\\training_callbacks/KERAS_check_best_model_weights.h5\n",
      "Epoch 00092: saving model to .\\training_callbacks/KERAS_check_model_last.h5\n",
      "Epoch 00092: saving model to .\\training_callbacks/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "59261/59261 [==============================] - 1s - loss: 0.9773 - acc: 0.6743 - val_loss: 0.9833 - val_acc: 0.6697\n",
      "Epoch 94/100\n",
      "56320/59261 [===========================>..] - ETA: 0s - loss: 0.9745 - acc: 0.6758\n",
      "***callbacks***\n",
      "saving losses to .\\training_callbacks\\losses.log\n",
      "Epoch 00093: val_loss improved from 0.98331 to 0.98326, saving model to .\\training_callbacks/KERAS_check_best_model.h5\n",
      "Epoch 00093: val_loss improved from 0.98331 to 0.98326, saving model to .\\training_callbacks/KERAS_check_best_model_weights.h5\n",
      "Epoch 00093: saving model to .\\training_callbacks/KERAS_check_model_last.h5\n",
      "Epoch 00093: saving model to .\\training_callbacks/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59261/59261 [==============================] - 1s - loss: 0.9750 - acc: 0.6759 - val_loss: 0.9833 - val_acc: 0.6707\n",
      "Epoch 95/100\n",
      "56320/59261 [===========================>..] - ETA: 0s - loss: 0.9726 - acc: 0.6763\n",
      "***callbacks***\n",
      "saving losses to .\\training_callbacks\\losses.log\n",
      "Epoch 00094: val_loss improved from 0.98326 to 0.97902, saving model to .\\training_callbacks/KERAS_check_best_model.h5\n",
      "Epoch 00094: val_loss improved from 0.98326 to 0.97902, saving model to .\\training_callbacks/KERAS_check_best_model_weights.h5\n",
      "Epoch 00094: saving model to .\\training_callbacks/KERAS_check_model_last.h5\n",
      "Epoch 00094: saving model to .\\training_callbacks/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "59261/59261 [==============================] - 1s - loss: 0.9735 - acc: 0.6762 - val_loss: 0.9790 - val_acc: 0.6730\n",
      "Epoch 96/100\n",
      "56320/59261 [===========================>..] - ETA: 0s - loss: 0.9716 - acc: 0.6776\n",
      "***callbacks***\n",
      "saving losses to .\\training_callbacks\\losses.log\n",
      "Epoch 00095: val_loss improved from 0.97902 to 0.97794, saving model to .\\training_callbacks/KERAS_check_best_model.h5\n",
      "Epoch 00095: val_loss improved from 0.97902 to 0.97794, saving model to .\\training_callbacks/KERAS_check_best_model_weights.h5\n",
      "Epoch 00095: saving model to .\\training_callbacks/KERAS_check_model_last.h5\n",
      "Epoch 00095: saving model to .\\training_callbacks/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "59261/59261 [==============================] - 1s - loss: 0.9711 - acc: 0.6776 - val_loss: 0.9779 - val_acc: 0.6741\n",
      "Epoch 97/100\n",
      "56320/59261 [===========================>..] - ETA: 0s - loss: 0.9710 - acc: 0.6774\n",
      "***callbacks***\n",
      "saving losses to .\\training_callbacks\\losses.log\n",
      "Epoch 00096: val_loss improved from 0.97794 to 0.97555, saving model to .\\training_callbacks/KERAS_check_best_model.h5\n",
      "Epoch 00096: val_loss improved from 0.97794 to 0.97555, saving model to .\\training_callbacks/KERAS_check_best_model_weights.h5\n",
      "Epoch 00096: saving model to .\\training_callbacks/KERAS_check_model_last.h5\n",
      "Epoch 00096: saving model to .\\training_callbacks/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "59261/59261 [==============================] - 1s - loss: 0.9693 - acc: 0.6777 - val_loss: 0.9756 - val_acc: 0.6740\n",
      "Epoch 98/100\n",
      "56320/59261 [===========================>..] - ETA: 0s - loss: 0.9659 - acc: 0.6788\n",
      "***callbacks***\n",
      "saving losses to .\\training_callbacks\\losses.log\n",
      "Epoch 00097: val_loss improved from 0.97555 to 0.97418, saving model to .\\training_callbacks/KERAS_check_best_model.h5\n",
      "Epoch 00097: val_loss improved from 0.97555 to 0.97418, saving model to .\\training_callbacks/KERAS_check_best_model_weights.h5\n",
      "Epoch 00097: saving model to .\\training_callbacks/KERAS_check_model_last.h5\n",
      "Epoch 00097: saving model to .\\training_callbacks/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "59261/59261 [==============================] - 1s - loss: 0.9676 - acc: 0.6782 - val_loss: 0.9742 - val_acc: 0.6752\n",
      "Epoch 99/100\n",
      "56320/59261 [===========================>..] - ETA: 0s - loss: 0.9650 - acc: 0.6800\n",
      "***callbacks***\n",
      "saving losses to .\\training_callbacks\\losses.log\n",
      "Epoch 00098: val_loss improved from 0.97418 to 0.97140, saving model to .\\training_callbacks/KERAS_check_best_model.h5\n",
      "Epoch 00098: val_loss improved from 0.97418 to 0.97140, saving model to .\\training_callbacks/KERAS_check_best_model_weights.h5\n",
      "Epoch 00098: saving model to .\\training_callbacks/KERAS_check_model_last.h5\n",
      "Epoch 00098: saving model to .\\training_callbacks/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "59261/59261 [==============================] - 1s - loss: 0.9658 - acc: 0.6789 - val_loss: 0.9714 - val_acc: 0.6763\n",
      "Epoch 100/100\n",
      "56320/59261 [===========================>..] - ETA: 0s - loss: 0.9624 - acc: 0.6806- ETA: 0s - loss: 0.9628 - acc: 0.\n",
      "***callbacks***\n",
      "saving losses to .\\training_callbacks\\losses.log\n",
      "Epoch 00099: val_loss improved from 0.97140 to 0.96936, saving model to .\\training_callbacks/KERAS_check_best_model.h5\n",
      "Epoch 00099: val_loss improved from 0.97140 to 0.96936, saving model to .\\training_callbacks/KERAS_check_best_model_weights.h5\n",
      "Epoch 00099: saving model to .\\training_callbacks/KERAS_check_model_last.h5\n",
      "Epoch 00099: saving model to .\\training_callbacks/KERAS_check_model_last_weights.h5\n",
      "Epoch 00099: saving model to .\\training_callbacks/KERAS_check_model_epoch99.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "59261/59261 [==============================] - 1s - loss: 0.9639 - acc: 0.6803 - val_loss: 0.9694 - val_acc: 0.6762\n"
     ]
    }
   ],
   "source": [
    "model.load_weights(options.inputModel)\n",
    "model.summary()\n",
    "startlearningrate=0.0001\n",
    "adam = Adam(lr=startlearningrate)\n",
    "model.compile(optimizer=adam, loss=[yamlConfig['KerasLoss']], metrics=['accuracy'])\n",
    "\n",
    "callbacks=all_callbacks(stop_patience=1000, \n",
    "                        lr_factor=0.5,\n",
    "                        lr_patience=10,\n",
    "                        lr_epsilon=0.000001, \n",
    "                        lr_cooldown=2, \n",
    "                        lr_minimum=0.0000001,\n",
    "                        outputDir=os.curdir + '\\\\training_callbacks')\n",
    "\n",
    "history = model.fit(X_train_val, y_train_val, batch_size = 1024, epochs = 100,\n",
    "                validation_split = 0.25, shuffle = True, callbacks = callbacks.callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeRoc(features_val, labels, labels_val, model):\n",
    "    print('in makeRoc()')\n",
    "    if 'j_index' in labels: labels.remove('j_index')\n",
    "\n",
    "    predict_test = model.predict(features_val)\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "    \n",
    "    fpr = {}\n",
    "    tpr = {}\n",
    "    auc1 = {}\n",
    "    \n",
    "    plt.figure()       \n",
    "    for i, label in enumerate(labels):\n",
    "        df[label] = labels_val[:,i]\n",
    "        df[label + '_pred'] = predict_test[:,i]\n",
    "        \n",
    "        fpr[label], tpr[label], threshold = roc_curve(df[label],df[label+'_pred'])\n",
    "\n",
    "        auc1[label] = auc(fpr[label], tpr[label])\n",
    "            \n",
    "        plt.plot(tpr[label],fpr[label],label='%s tagger, AUC = %.1f%%'%(label.replace('j_',''),auc1[label]*100.))\n",
    "    plt.semilogy()\n",
    "    plt.xlabel(\"Signal Efficiency\")\n",
    "    plt.ylabel(\"Background Efficiency\")\n",
    "    plt.ylim(0.001,1)\n",
    "    plt.grid(True)\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.figtext(0.25, 0.90,'hls4ml',fontweight='bold', wrap=True, horizontalalignment='right', fontsize=14)\n",
    "    #plt.figtext(0.35, 0.90,'preliminary', style='italic', wrap=True, horizontalalignment='center', fontsize=14) \n",
    "    plt.savefig(\"mygraph.png\")\n",
    "#     plt.savefig('%s/ROC.pdf'%(options.outputDir))\n",
    "#     plt.savefig('%s/ROC.pdf' %(outputDir))\n",
    "    return predict_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot ROC curve\n",
      "in makeRoc()\n"
     ]
    }
   ],
   "source": [
    "print(\"Plot ROC curve\")\n",
    "y_predict = makeRoc(X_test, labels, y_test, model)"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learningCurve(history):\n",
    "    plt.figure(figsize=(10,8))\n",
    "    plt.plot(history.history['loss'], linewidth=1)\n",
    "    plt.plot(history.history['val_loss'], linewidth=1)\n",
    "    plt.title('Model Loss over Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['training sample loss','validation sample loss'])\n",
    "    plt.savefig('Learning_curve.pdf')\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anrun\\anaconda3\\envs\\EPE_ML\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "learningCurve(history)"
   ]
  },
  {
   "attachments": {
    "GRAPH.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![GRAPH.png](attachment:GRAPH.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
